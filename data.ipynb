{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_blobs\n",
    "#import spotipy\n",
    "#from spotipy.oauth2 import SpotifyClientCredentials\n",
    "#from collections import defaultdict\n",
    "#from kaggle import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Hp\\Desktop\\dataset\\Spotify_project\\data (2).csv')\n",
    "genre_data = pd.read_csv(r'C:\\Users\\Hp\\Desktop\\dataset\\Spotify_project\\data_by_genres.csv')\n",
    "artist_data = pd.read_csv(r'C:\\Users\\Hp\\Desktop\\dataset\\Spotify_project\\data_by_artist.csv')\n",
    "yaer_data = pd.read_csv(r'C:\\Users\\Hp\\Desktop\\dataset\\Spotify_project\\data_by_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.isnull().sum())\n",
    "#print(genre_data.isnull().sum())\n",
    "#print(artist_data.isnull().sum())\n",
    "#print(yaer_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data', data.columns)\n",
    "print('year', yaer_data.columns)\n",
    "print('artist', artist_data.columns)\n",
    "print('genre', genre_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decade column in data representing the decade of each track using apply() and a lambda function.\n",
    "data['decade'] = data['year'].apply(lambda x: str(x)[:-1] + \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of tracks across different decades using a count plot: sns.countplot(data['decade']).\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(data['decade'])\n",
    "plt.title('Track Count by Decade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.treemap(data,path=[px.Constant('artists'),'artists','name'],values='popularity',title='<b>TreeMap of Singers Playlist')\n",
    "fig.update_traces(root_color='lightgreen')\n",
    "fig.update_layout(title_x=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the trends of various sound features (acousticness, danceability, energy, instrumentalness, liveness, valence) over decades using a line plot: \n",
    "# px.line(year_data, x='year', y=sound_features, title='Trend of various sound features over decades').\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=yaer_data, x='year', y='acousticness', label='acousticness')\n",
    "sns.lineplot(data=yaer_data, x='year', y='danceability', label='danceability')\n",
    "sns.lineplot(data=yaer_data, x='year', y='energy', label='energy')\n",
    "sns.lineplot(data=yaer_data, x='year', y='instrumentalness', label='instrumentalness')\n",
    "sns.lineplot(data=yaer_data, x='year', y='liveness', label='liveness')\n",
    "sns.lineplot(data=yaer_data, x='year', y='valence', label='valence')\n",
    "plt.title('Trend of various sound features over decades')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the trend of loudness over decades using a line plot: px.line(year_data, x='year', y='loudness', title='Trend of loudness over decades').\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=yaer_data, x='year', y='loudness')\n",
    "plt.title('Trend of loudness over decades')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the top 10 genres based on popularity and plot the trends of various sound features (valence, energy, danceability, acousticness) for these genres using a grouped bar chart: px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group', title='Trend of various sound features over top 10 genres').\n",
    "top10_genres = genre_data.sort_values('popularity', ascending=False).head(10)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top10_genres, x='genres', y='valence', label='valence')\n",
    "sns.barplot(data=top10_genres, x='genres', y='energy', label='energy')\n",
    "sns.barplot(data=top10_genres, x='genres', y='danceability', label='danceability')\n",
    "sns.barplot(data=top10_genres, x='genres', y='acousticness', label='acousticness')\n",
    "plt.title('Trend of various sound features over top 10 genres')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With plotly express\n",
    "# Identify the top 10 genres based on popularity\n",
    "top10_genres = genre_data.sort_values('popularity', ascending=False).head(10)\n",
    "\n",
    "# Plot the trends of various sound features using a grouped bar chart\n",
    "fig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'],\n",
    "             barmode='group', title='Trend of Various Sound Features Over Top 10 Genres',\n",
    "             labels={'value': 'Score', 'genres': 'Genres'},\n",
    "             color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_copy = genre_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud of the genres present in the dataset using the WordCloud library: WordCloud(width=800, height=800, background_color='white', stopwords=stopwords, max_words=40, min_font_size=10).generate(comment_words)\n",
    "\n",
    "# Combine all genres into a single string\n",
    "comment_words = ' '.join(genre_copy['genres'])\n",
    "# Define stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=800,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      max_words=40,\n",
    "                      min_font_size=10).generate(comment_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the word cloud\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud of Genres\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_copy = artist_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud of the artists present in the dataset using the WordCloud library: WordCloud(width=800, height=800, background_color='white', stopwords=stopwords, min_word_length=3, max_words=40, min_font_size=10).generate(comment_words).\n",
    "\n",
    "# Combine all artists into a single string\n",
    "comment_words = ' '.join(artist_copy['artists'])\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=800,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      min_word_length=3,\n",
    "                      max_words=40,\n",
    "                      min_font_size=10).generate(comment_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the word cloud of the artists: plt.imshow(wordcloud).\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud of Artists\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 10 artists with the most songs produced and display the count and artist name: \n",
    "# top10_most_song_produced_artists[['count','artists']].sort_values('count', ascending=False).\n",
    "top_10_artists_most_songs = artist_data.sort_values('count', ascending=False).head(10)\n",
    "print(top_10_artists_most_songs[['count', 'artists']].sort_values('count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top 10 artists with the highest popularity score and display the popularity score and artist name: \n",
    "# top10_popular_artists[['popularity','artists']].sort_values('popularity', ascending=False).\n",
    "top_10_artist_high_popularity = artist_data.sort_values('popularity', ascending=False).head(10)\n",
    "print(top_10_artist_high_popularity[['popularity', 'artists']].sort_values('popularity', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- data is a dataset containing information about tracks, artists, and genres.\n",
    "- yaer_data is a dataset containing information about tracks over the years.\n",
    "- artist_data is a dataset containing information about artists.\n",
    "- genre_data is a dataset containing information about genres.\n",
    "\n",
    "We found similarity between the datasets, the same column on each data\n",
    "We can :\n",
    "- Merge the data using the 'artists' column to find the relationship between the artists and genres.\n",
    "- Merge the artist_data and genre_data on the 'artists' column: artist_genre_data.\n",
    "\n",
    "we can have one big data \n",
    "we can use sql server or other app to view and manage a relation between tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features for clustering :\n",
    "features = ['mode', 'acousticness', 'danceability', 'duration_ms',\n",
    "       'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness',\n",
    "       'tempo', 'valence', 'popularity', 'key']\n",
    "\n",
    "# Preprocessing :\n",
    "standar_scaler = StandardScaler()\n",
    "scaler_genre_data = standar_scaler.fit_transform(genre_copy[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data.shape, scaler_genre_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-means model with 12 clusters\n",
    "kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "genre_data['cluster'] = kmeans.fit_predict(scaler_genre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cluster labels to each genre\n",
    "print(genre_data[['genres', 'cluster']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-SNE (t-distributed Stochastic Neighbor Embedding) technique is excellent for reducing high-dimensional data into two or three dimensions for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters of genres using t-SNE dimensionality reduction technique.\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(scaler_genre_data)\n",
    "genre_data['x'] = tsne.fit_transform(scaler_genre_data)[:, 0]\n",
    "genre_data['y'] = tsne.fit_transform(scaler_genre_data)[:, 1]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot with clusters colored and display genre information on hover.\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='x', y='y', hue='cluster', palette='viridis', data=genre_data, legend='full')\n",
    "plt.title('t-SNE Clustering of Genres')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title='Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a K-means clustering model on the song data using 25 clusters.\n",
    "features_data = ['valence', 'acousticness', 'danceability', 'duration_ms', \n",
    "                 'energy', 'key', 'liveness', 'popularity', 'speechiness', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data[features_data].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=25, random_state=42)\n",
    "data_features['cluster'] = kmeans.fit_predict(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cluster labels to each song\n",
    "data_query = data_features.copy()\n",
    "data_query['name']= data['name']\n",
    "print(data_query[['name', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the clusters of songs using PCA dimensionality reduction technique.\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data[features_data])\n",
    "data_features['pca_1'] = pca_result[:, 0]\n",
    "data_features['pca_2'] = pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot with clusters colored and display song information on hover.\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=data_features, x='pca_1', y='pca_2', hue='cluster', \n",
    "                palette='tab20', legend='full', \n",
    "                s=10, alpha=1)\n",
    "plt.title('PCA Clustering of Songs')\n",
    "plt.xlabel('PCA Dimension 1')\n",
    "plt.ylabel('PCA Dimension 2')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', title='Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'pca__n_components': [2, 3, 4, 5, 10]}                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GridSearchCV to find the best parameters based on explained variance\n",
    "pipeline = Pipeline([('pca', PCA()), ('kmeans', KMeans(n_clusters=25, random_state=42))])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(data_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation explained variance score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the explained variance on the entire dataset\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "transformed_data = best_pipeline.transform(data_features)\n",
    "explained_variance = best_pipeline.named_steps['pca'].explained_variance_ratio_\n",
    "print(f\"Explained variance ratio by component: {explained_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "mean_scores = results['mean_test_score']\n",
    "params = [p['pca__n_components'] for p in results['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(params, mean_scores, marker='o')\n",
    "plt.title('Mean Explained Variance Scores vs. Number of PCA Components')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Mean Explained Variance Score')\n",
    "plt.xticks(params)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline includes a StandardScaler for feature normalization and PCA for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    return row.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").strip()\n",
    "\n",
    "# Apply the function to the 'artists' column\n",
    "data_transformed['artists'] = data_transformed['artists'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_art_song = data_transformed[['artists', 'name']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Function to find song details from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_song_from_data():\n",
    "    # Input song name and artist name\n",
    "    song_name = input(\"Enter the name of the song: \").strip()\n",
    "    \n",
    "    # Check ifsong name exist in the data\n",
    "    row = data[(data['name'].str.lower() == song_name.lower())]\n",
    "\n",
    "    # If the song and artist are not found, return None\n",
    "    if row.empty:\n",
    "        return None\n",
    "\n",
    "    # Extract song details if song and artist exist\n",
    "    song_details = row.iloc[0].to_dict()\n",
    "\n",
    "    return song_details\n",
    "\n",
    "# Find the song details using the find_song_from_data function\n",
    "print(find_song_from_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Define a function get_mean_vector that calculates the mean vector of numerical features for a given list of songs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_encoded = data.copy()\n",
    "data_encoded['id_encoded'] = le.fit_transform(data['id'])\n",
    "data_encoded.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_mean_vector function :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(songs_id, data):\n",
    "    # Filter the data set to include only the songs with the given IDs\n",
    "    numerical_data = data[data['id_encoded'].isin(songs_id)]\n",
    "    # List of numerical features\n",
    "    numerical_features = [\n",
    "        'duration_ms', 'popularity', 'danceability', 'energy', \n",
    "        'instrumentalness', 'explicit', 'liveness', 'mode',\n",
    "        'key', 'loudness', 'speechiness', 'acousticness', 'valence', 'tempo'\n",
    "    ]\n",
    " # Calculate the mean vector of numerical features\n",
    "    mean_vector = numerical_data[numerical_features].mean()\n",
    "\n",
    "    return mean_vector\n",
    "\n",
    "# Example usage of get_mean_vector function\n",
    "songs_id = [96623, 85809, 123331]  # List of song IDs to include in the calculation\n",
    "data = data_encoded\n",
    "mean_vector = get_mean_vector(songs_id, data_encoded)\n",
    "print(\"Mean Vector of Numerical Features:\")\n",
    "print(mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "8 . Define a function flatten_dict_list that flattens a list of dictionaries into a dictionary \n",
    "\n",
    "with grouped keys and corresponding lists of values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict_list(data):\n",
    "    dict_list = data.to_dict(orient='records')\n",
    "\n",
    "    flattened_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Define a function recommend_songs that recommends similar songs based on a given list of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(song_ids, data, top_n):\n",
    "    from scipy.spatial.distance import cosine\n",
    "    mean_vector_song = get_mean_vector(song_ids, data)\n",
    "\n",
    "    numerical_features = ['duration_ms', 'popularity', 'danceability', 'energy', \n",
    "        'instrumentalness', 'explicit', 'liveness', 'mode', 'key', 'loudness', \n",
    "        'speechiness', 'acousticness', 'valence', 'tempo']\n",
    "    \n",
    "    data_encoded_vectors = data[numerical_features]\n",
    "    similarities = data_encoded_vectors.apply(lambda row: 1 - cosine(mean_vector_song, row), axis=1)\n",
    "    recommendations = data.iloc[similarities.nlargest(top_n + len(song_ids)).index]\n",
    "    # Exclude the original songs from recommendations\n",
    "    recommendations = recommendations[~recommendations['id_encoded'].isin(song_ids)]\n",
    "    display_data = recommendations[['id_encoded', 'artists', 'name', 'year']]\n",
    "    return display_data.head(top_n)\n",
    "\n",
    "# Example usage of recommend_songs function\n",
    "recommended_songs = recommend_songs(song_ids= [96623, 85809] , data=data_encoded, top_n=3)\n",
    "print(\"Recommended Songs:\")\n",
    "print(recommended_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Implement the recommendation system by following the instructions provided within each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
